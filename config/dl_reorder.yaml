name: "dl_reorder"

feature_definition:
  use_norm_features: False # whether to use normalized features

data_loader:
  batch_size: 512
  # Define how each data batch is sampled from multiple datasets and/or people
  # option: "across_dataset", "within_dataset", "across_person", "within_person"
  generate_by: "across_dataset" 
  
  mixup: "across" # option to mixup data: null, "across" (person or dataset), "within" (person or dataset)
  mixup_alpha: 0.2 # the strongness of mixup. from 0 to 1

model_params:
  arch: "1dCNN" # model architecture
  # input dimension
  # 2: a multi-channel time series data (for models like 1dCNN)
  # 3: a single-channel image data (for models like 2dCNN)
  input_dim: 2
  conv_shapes: [8,8,8] # a list of convolutional layers shapes
  embedding_size: 16 # vector length of the feature embedding network output
  flag_y_vector: True # True: one hot vector on y for regular training
  num_reorder_class: 200 # number of pre-determined reorder class
  rate_of_reorder: 0.7 # rate of the data are reordered during the training, and (1-rate) of the data are regular
  weight_of_reorder: 0.2 # the weight of reorder task loss in the aggregated loss function. 1 means the same weight as the main task

training_params:
  optimizer: "Adam" # option: SGD or Adam
  learning_rate: 0.001
  epochs: 200
  steps_per_epoch: 100 # number of batches per epoch
  cos_annealing_step: 20
  cos_annealing_decay: 0.95
  best_epoch_strategy: "direct" # option: direct or on_test
  verbose: 0
  skip_training: False
